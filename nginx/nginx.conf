include /etc/nginx/modules/*.conf;

user nginx nginx;
pid /var/run/nginx.pid;

events {
    worker_connections 4096;
    use epoll;
}

worker_processes auto;
worker_cpu_affinity auto;
worker_rlimit_nofile 65535;

http {

    log_format json escape=json '{'
      '"@timestamp": "$time_iso8601",'
      '"core": {'
        '"body_bytes_sent": "$body_bytes_sent",'
        '"status": "$status",'
        '"server_name": "$server_name",'
        '"remote_addr": "$remote_addr",'
        '"remote_user": "$remote_user",'
        '"request": "$request",'
        '"http": {'
          '"http_referer": "$http_referer",'
          '"http_user_agent": "$http_user_agent",'
          '"http_x_forwarded_for": "$http_x_forwarded_for"'
        '}'
      '}'
    '}';

    # Determine whether a request comes from a human, a search crawler or another bot.
    map $http_user_agent $is_non_search_bot {
        default '';
        ~*(google|bing|facebook|Facebot) '';
        ~*(http|crawler|spider|bot|search|ForusP|Wget/|Python-urllib|PHPCrawl|bGenius) 'bot';
    }
    # Rate limit bots (that are not search spiders) to one PHP request per second.
    # An empty '$limit_bots' would disable rate limiting for this requests
    limit_req_zone $is_non_search_bot zone=bots:1m rate=1r/s;
    limit_req_log_level error;
    limit_req_status 429;

    proxy_http_version 1.1;
    proxy_set_header Connection "";
    more_clear_headers Server;

    include       mime.types;
    default_type  application/octet-stream;

    include /etc/nginx/conf.d/*.conf;
}
